{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kHtLRd4LcUf",
        "outputId": "969c66ad-e622-403e-a635-eab1620b6827"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-510\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  fonts-nanum\n",
            "0 upgraded, 1 newly installed, 0 to remove and 27 not upgraded.\n",
            "Need to get 9,599 kB of archives.\n",
            "After this operation, 29.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 fonts-nanum all 20180306-3 [9,599 kB]\n",
            "Fetched 9,599 kB in 2s (4,327 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 129496 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20180306-3_all.deb ...\n",
            "Unpacking fonts-nanum (20180306-3) ...\n",
            "Setting up fonts-nanum (20180306-3) ...\n",
            "Processing triggers for fontconfig (2.13.1-2ubuntu3) ...\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 10 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/usr/share/fonts/truetype: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/nanum: skipping, looped directory detected\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4RTVL1yMH9j"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AXORQq15MFFK"
      },
      "outputs": [],
      "source": [
        "from matplotlib import font_manager\n",
        "for font in font_manager.fontManager.ttflist:\n",
        "    if 'Nanum' in font.name:\n",
        "        print(font.name, font.fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poapmFa1MHTg"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('font', family='NanumBarunGothic') \n",
        "plt.rcParams['axes.unicode_minus'] = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSH6KuZk8Y4s",
        "outputId": "355ab226-55db-4306-a643-2b348c243b86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_hPbd5d84ts"
      },
      "outputs": [],
      "source": [
        "cropped_img_df = pd.read_csv('/content/drive/MyDrive/공유폴더/angle_cropped_img/angle_cropped_df.csv', index_col = 0)\n",
        "info_df = pd.read_csv('/content/drive/MyDrive/공유폴더/csv/kcar_info.csv', index_col = 0)\n",
        "unique_df = pd.read_csv('/content/drive/MyDrive/공유폴더/csv/same_img_Euclidean_Distance.csv', index_col = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCja55_cOzTk"
      },
      "source": [
        "# ReidHelper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJpR90UDO-0D",
        "outputId": "e066b879-2c0d-4fc9-e16f-0b9f5ff5837a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.13.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf<4,>=3.20.2\n",
            "  Downloading protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.8/dist-packages (from onnx) (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.8/dist-packages (from onnx) (1.21.6)\n",
            "Installing collected packages: protobuf, onnx\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed onnx-1.13.0 protobuf-3.20.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnxoptimizer\n",
            "  Downloading onnxoptimizer-0.3.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (606 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m606.4/606.4 KB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: onnx in /usr/local/lib/python3.8/dist-packages (from onnxoptimizer) (1.13.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.8/dist-packages (from onnx->onnxoptimizer) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.8/dist-packages (from onnx->onnxoptimizer) (4.4.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.20.2 in /usr/local/lib/python3.8/dist-packages (from onnx->onnxoptimizer) (3.20.3)\n",
            "Installing collected packages: onnxoptimizer\n",
            "Successfully installed onnxoptimizer-0.3.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnxsim\n",
            "  Downloading onnxsim-0.4.13-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rich\n",
            "  Downloading rich-13.3.1-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.0/239.0 KB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: onnx in /usr/local/lib/python3.8/dist-packages (from onnxsim) (1.13.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.20.2 in /usr/local/lib/python3.8/dist-packages (from onnx->onnxsim) (3.20.3)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.8/dist-packages (from onnx->onnxsim) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.8/dist-packages (from onnx->onnxsim) (4.4.0)\n",
            "Collecting markdown-it-py<3.0.0,>=2.1.0\n",
            "  Downloading markdown_it_py-2.1.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pygments<3.0.0,>=2.14.0\n",
            "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: pygments, mdurl, markdown-it-py, rich, onnxsim\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.6.1\n",
            "    Uninstalling Pygments-2.6.1:\n",
            "      Successfully uninstalled Pygments-2.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed markdown-it-py-2.1.0 mdurl-0.1.2 onnxsim-0.4.13 pygments-2.14.0 rich-13.3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnxruntime-gpu\n",
            "  Downloading onnxruntime_gpu-1.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (115.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from onnxruntime-gpu) (3.20.3)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.8/dist-packages (from onnxruntime-gpu) (1.12)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from onnxruntime-gpu) (1.7.1)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 KB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from onnxruntime-gpu) (23.0)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.8/dist-packages (from onnxruntime-gpu) (1.21.6)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 KB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->onnxruntime-gpu) (1.2.1)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime-gpu\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-gpu-1.13.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from yacs) (6.0)\n",
            "Installing collected packages: yacs\n",
            "Successfully installed yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "!pip install onnx\n",
        "!pip install onnxoptimizer\n",
        "!pip install onnxsim\n",
        "!pip install onnxruntime-gpu\n",
        "!pip install yacs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpfSLiCRAedw"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import onnxruntime\n",
        "\n",
        "class ReidHelper:\n",
        "\n",
        "    def __init__(self,model_path):\n",
        "        self.size = (256,256)\n",
        "        ep_list = ['CUDAExecutionProvider']\n",
        "        self.sess = onnxruntime.InferenceSession(model_path,providers = ep_list)\n",
        "\n",
        "    def infer(self, image_np):\n",
        "        input_name = self.sess.get_inputs()[0].name\n",
        "\n",
        "        image = self.preprocess(image_np)\n",
        "\n",
        "        feat = self.sess.run(None, {input_name: image})[0]\n",
        "        feat = self.normalize(feat, axis=1)\n",
        "        \n",
        "        return feat\n",
        "\n",
        "    def preprocess(self, image_np):\n",
        "\n",
        "        # the model expects RGB inputs\n",
        "        original_image = image_np[:, :, ::-1]\n",
        "\n",
        "        # Apply pre-processing to image.\n",
        "        resize_width = self.size[0]\n",
        "        resize_height = self.size[1]\n",
        "        img = cv2.resize(original_image, (resize_width, resize_height), interpolation=cv2.INTER_CUBIC)\n",
        "        img = img.astype(\"float32\").transpose(2, 0, 1)[np.newaxis]  # (1, 3, h, w)\n",
        "        return img\n",
        "\n",
        "\n",
        "    def normalize(self, nparray, order=2, axis=-1):\n",
        "        \"\"\"Normalize a N-D numpy array along the specified axis.\"\"\"\n",
        "        norm = np.linalg.norm(nparray, ord=order, axis=axis, keepdims=True)\n",
        "        return nparray / (norm + np.finfo(np.float32).eps)\n",
        "\n",
        "# 거리 계산 함수\n",
        "def calc_distance(feat1, feat2):\n",
        "    distance = np.linalg.norm(feat1 - feat2)\n",
        "    return distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkJh9MHTPE1E"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_M17UUL-crbW"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import random\n",
        "import cv2\n",
        "\n",
        "\n",
        "def random_df(angle = '정면', path_df = cropped_img_df, unique_df = unique_df):\n",
        "    \n",
        "    path_dict = {'small':'/content/drive/MyDrive/공유폴더/fast-reid/outputs/VeRi_Baseline/baseline_R50.onnx',\n",
        "                'middel':'/content/drive/MyDrive/공유폴더/fast-reid/outputs/VehicleID_Baseline/baseline_R50.onnx',\n",
        "                'large':'/content/drive/MyDrive/공유폴더/fast-reid/outputs/VERI_Wild_Baseline/baseline_R50.onnx'\n",
        "                 }\n",
        "    \n",
        "    idx = 0\n",
        "    result_df = pd.DataFrame(columns = ['case', 'target_model', 'car_model', 'small_distance', 'middle_distance', 'large_distance', 'file_path'])\n",
        "    case_idx = 0\n",
        "    num = 0\n",
        "\n",
        "    angle_df = path_df[path_df['angle'] == angle].reset_index(drop=True)\n",
        "    path_v = angle_df['class'].value_counts()\n",
        "    cls_over5= path_v[path_v>=5].keys()\n",
        "    \n",
        "    helper_small = ReidHelper(path_dict['small'])\n",
        "    helper_middle = ReidHelper(path_dict['middle'])\n",
        "    helper_large = ReidHelper(path_dict['large'])\n",
        "    \n",
        "\n",
        "    for cls in cls_over5:\n",
        "        select_path = angle_df[angle_df['class']== cls]['file_path'].values\n",
        "        select_length = len(select_path)\n",
        "        \n",
        "        feat1_small = None\n",
        "        feat1_middle = None\n",
        "        feat1_large = None\n",
        "\n",
        "        for index, file_path in enumerate(select_path):\n",
        "            car_img = cv2.imread(file_path)\n",
        "            feat_small = helper_small.infer(car_img)\n",
        "            feat_middle = helper_middle.infer(car_img)\n",
        "            feat_large = helper_large.infer(car_img)\n",
        "\n",
        "            if index == 0:\n",
        "                idx +=1\n",
        "                feat1_small = feat_small\n",
        "                feat1_middle =feat_middle\n",
        "                feat1_large = feat_large\n",
        "                ex = angle_df[angle_df['class']==cls].iloc[0]\n",
        "                result_df.loc[idx,:] = [case_idx, cls, cls, 0, 0, 0,  file_path]\n",
        "                num += 1\n",
        "            else:\n",
        "                idx +=1\n",
        "                small_distance = calc_distance(feat1_small, feat_small)\n",
        "                middle_distance = calc_distance(feat1_middle, feat_middle)\n",
        "                large_distance = calc_distance(feat1_large, feat_large)\n",
        "                result_df.loc[idx,:] = [case_idx, cls, cls, small_distance, middle_distance, large_distance,  file_path]\n",
        "                num += 1\n",
        "        \n",
        "        select_can = list(angle_df[angle_df['class'] != cls].index)\n",
        "        \n",
        "        random100 = random.sample(select_can, 100 - select_length)\n",
        "\n",
        "        for gal_index in random100:\n",
        "            idx += 1\n",
        "            gal = angle_df.loc[gal_index]\n",
        "            car_img = cv2.imread(gal['file_path'])\n",
        "            feat_small = helper_small.infer(car_img)\n",
        "            feat_middle = helper_middle.infer(car_img)\n",
        "            feat_large = helper_large.infer(car_img)\n",
        "            small_distance = calc_distance(feat1_small, feat_small)\n",
        "            middle_distance = calc_distance(feat1_middle, feat_middle)\n",
        "            large_distance = calc_distance(feat1_large, feat_large)\n",
        "            result_df.loc[idx,:] = [case_idx, cls, gal['class'], small_distance, middle_distance, large_distance,  gal['file_path']]\n",
        "            num += 1\n",
        "        \n",
        "        print(num)\n",
        "    \n",
        "    return result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "_8L60kiXgBm6",
        "outputId": "d8172a94-5103-4f65-f7a0-f7294265e8a1"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-da5306d8b5fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/공유폴더/csv/정면.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'후면'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/공유폴더/csv/후면.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'측면'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-2bef060f7252>\u001b[0m in \u001b[0;36mrandom_df\u001b[0;34m(angle, path_df, unique_df)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mcls_over5\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpath_v\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpath_v\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mhelper_small\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReidHelper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'small'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mhelper_middle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReidHelper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'middle'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mhelper_large\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReidHelper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'large'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-6840fb68dd3e>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mep_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'CUDAExecutionProvider'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monnxruntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInferenceSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mproviders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mep_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_bytes, sess_options, providers, provider_options, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_inference_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproviders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprovider_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisabled_optimizers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_fallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py\u001b[0m in \u001b[0;36m_create_inference_session\u001b[0;34m(self, providers, provider_options, disabled_optimizers)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;31m# initialize the C++ InferenceSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproviders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprovider_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisabled_optimizers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "df = random_df()\n",
        "df.to_csv('/content/drive/MyDrive/공유폴더/csv/정면.csv')\n",
        "df = random_df(angle = '후면')\n",
        "df.to_csv('/content/drive/MyDrive/공유폴더/csv/후면.csv')\n",
        "df = random_df(angle = '측면')\n",
        "df.to_csv('/content/drive/MyDrive/공유폴더/csv/측면.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoB6_ifatuv5"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import random\n",
        "import cv2\n",
        "\n",
        "def random_df(angle = '정면', sample_num=100, path_df = cropped_img_df, unique_df = unique_df):\n",
        "    \n",
        "    path_dict = {'small':'/content/drive/MyDrive/공유폴더/fast-reid/outputs/VehicleID_Baseline/baseline_R50.onnx',\n",
        "                 'middle':'/content/drive/MyDrive/공유폴더/fast-reid/outputs/VeRi_Baseline/baseline_R50.onnx',\n",
        "                 'large':'/content/drive/MyDrive/공유폴더/fast-reid/outputs/VERI_Wild_Baseline/baseline_R50.onnx'\n",
        "                 }\n",
        "    \n",
        "    idx = 0\n",
        "    result_df = pd.DataFrame(columns = ['case', 'target_model', 'car_model', 'small_distance', 'middle_distance', 'large_distance', 'file_path'])\n",
        "    case_idx = 0\n",
        "    num = 0\n",
        "\n",
        "    angle_df = path_df[path_df['angle'] == angle].reset_index(drop=True)\n",
        "    path_v = angle_df['class'].value_counts()\n",
        "    cls_over5= path_v[path_v>=5].keys()\n",
        "    \n",
        "    helper_small = ReidHelper(path_dict['small'])\n",
        "    helper_middle = ReidHelper(path_dict['middle'])\n",
        "    helper_large = ReidHelper(path_dict['large'])\n",
        "    \n",
        "\n",
        "    for cls in cls_over5:\n",
        "        select_path = angle_df[angle_df['class']== cls]['file_path'].values\n",
        "        select_length = len(select_path)\n",
        "        select_color = angle_df[angle_df['class']== cls]['color'].values[0]\n",
        "\n",
        "        feat1_small = None\n",
        "        feat1_middle = None\n",
        "        feat1_large = None\n",
        "\n",
        "        for index, file_path in enumerate(select_path):\n",
        "            car_img = cv2.imread(file_path)\n",
        "            feat_small = helper_small.infer(car_img)\n",
        "            feat_middle = helper_middle.infer(car_img)\n",
        "            feat_large = helper_large.infer(car_img)\n",
        "\n",
        "            if index == 0:\n",
        "                idx +=1\n",
        "                feat1_small = feat_small\n",
        "                feat1_middle =feat_middle\n",
        "                feat1_large = feat_large\n",
        "                ex = angle_df[angle_df['class']==cls].iloc[0]\n",
        "                result_df.loc[idx,:] = [case_idx, cls, cls, 0, 0, 0,  file_path]\n",
        "                \n",
        "            else:\n",
        "                idx +=1\n",
        "                small_distance = calc_distance(feat1_small, feat_small)\n",
        "                middle_distance = calc_distance(feat1_middle, feat_middle)\n",
        "                large_distance = calc_distance(feat1_large, feat_large)\n",
        "                result_df.loc[idx,:] = [case_idx, cls, cls, small_distance, middle_distance, large_distance,  file_path]\n",
        "                \n",
        "        \n",
        "        select_can = list(angle_df[(angle_df['class'] != cls) & (angle_df['color'] == select_color)].index)\n",
        "        random100 = random.sample(select_can, sample_num - select_length)\n",
        "\n",
        "        for gal_index in random100:\n",
        "            idx += 1\n",
        "            gal = angle_df.loc[gal_index]\n",
        "            car_img = cv2.imread(gal['file_path'])\n",
        "            feat_small = helper_small.infer(car_img)\n",
        "            feat_middle = helper_middle.infer(car_img)\n",
        "            feat_large = helper_large.infer(car_img)\n",
        "            small_distance = calc_distance(feat1_small, feat_small)\n",
        "            middle_distance = calc_distance(feat1_middle, feat_middle)\n",
        "            large_distance = calc_distance(feat1_large, feat_large)\n",
        "            result_df.loc[idx,:] = [case_idx, cls, gal['class'], small_distance, middle_distance, large_distance,  gal['file_path']]\n",
        "        num += 1            \n",
        "        \n",
        "        print(num)\n",
        "    \n",
        "    return result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYxlip-NXWZS"
      },
      "outputs": [],
      "source": [
        "df = random_df(sample_num=90)\n",
        "df.to_csv('/content/drive/MyDrive/공유폴더/csv/정면_같은색.csv')\n",
        "df = random_df(angle = '후면')\n",
        "df.to_csv('/content/drive/MyDrive/공유폴더/csv/후면_같은색.csv')\n",
        "df = random_df(angle = '측면')\n",
        "df.to_csv('/content/drive/MyDrive/공유폴더/csv/측면_같은색.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktDSKcjBKfrG"
      },
      "outputs": [],
      "source": [
        "angle_df = cropped_img_df[cropped_img_df['angle'] == '후면'].reset_index(drop=True)\n",
        "angle_df['size'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0gsoXFlK6Pe"
      },
      "outputs": [],
      "source": [
        "angle_df[angle_df['size']=='경차']['class'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmwKKLxU0iMb"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import random\n",
        "import cv2\n",
        "\n",
        "def random_df(angle = '정면', sample_num=100, path_df = cropped_img_df, unique_df = unique_df):\n",
        "    \n",
        "    path_dict = {'small':'/content/drive/MyDrive/공유폴더/fast-reid/outputs/VehicleID_Baseline/baseline_R50.onnx',\n",
        "                 'middle':'/content/drive/MyDrive/공유폴더/fast-reid/outputs/VeRi_Baseline/baseline_R50.onnx',\n",
        "                 'large':'/content/drive/MyDrive/공유폴더/fast-reid/outputs/VERI_Wild_Baseline/baseline_R50.onnx'\n",
        "                 }\n",
        "    \n",
        "    idx = 0\n",
        "    result_df = pd.DataFrame(columns = ['case', 'target_model', 'car_model', 'small_distance', 'middle_distance', 'large_distance', 'file_path', 'same'])\n",
        "    case_idx = 0\n",
        "    num = 0\n",
        "\n",
        "    angle_df = path_df[path_df['angle'] == angle].reset_index(drop=True)\n",
        "    path_v = angle_df['class'].value_counts()\n",
        "    cls_over5= path_v[path_v>=5].keys()\n",
        "    \n",
        "    helper_small = ReidHelper(path_dict['small'])\n",
        "    helper_middle = ReidHelper(path_dict['middle'])\n",
        "    helper_large = ReidHelper(path_dict['large'])\n",
        "    \n",
        "\n",
        "    for cls in cls_over5:\n",
        "        select_path = angle_df[angle_df['class']== cls]['file_path'].values\n",
        "        select_length = len(select_path)\n",
        "        select_color = angle_df[angle_df['class']== cls]['color'].values[0]\n",
        "\n",
        "        feat1_small = None\n",
        "        feat1_middle = None\n",
        "        feat1_large = None\n",
        "\n",
        "        for index, file_path in enumerate(select_path):\n",
        "            car_img = cv2.imread(file_path)\n",
        "            feat_small = helper_small.infer(car_img)\n",
        "            feat_middle = helper_middle.infer(car_img)\n",
        "            feat_large = helper_large.infer(car_img)\n",
        "\n",
        "            if index == 0:\n",
        "                idx +=1\n",
        "                feat1_small = feat_small\n",
        "                feat1_middle =feat_middle\n",
        "                feat1_large = feat_large\n",
        "                ex = angle_df[angle_df['class']==cls].iloc[0]\n",
        "                result_df.loc[idx,:] = [case_idx, cls, cls, 0, 0, 0,  file_path, 0]\n",
        "                \n",
        "            else:\n",
        "                idx +=1\n",
        "                small_distance = calc_distance(feat1_small, feat_small)\n",
        "                middle_distance = calc_distance(feat1_middle, feat_middle)\n",
        "                large_distance = calc_distance(feat1_large, feat_large)\n",
        "                result_df.loc[idx,:] = [case_idx, cls, cls, small_distance, middle_distance, large_distance,  file_path, 0]\n",
        "                \n",
        "        \n",
        "        select_can = list(angle_df[(angle_df['class'] != cls) & (angle_df['color'] != select_color)].index)\n",
        "        random100 = random.sample(select_can, sample_num - select_length)\n",
        "\n",
        "        for gal_index in random100:\n",
        "            idx += 1\n",
        "            gal = angle_df.loc[gal_index]\n",
        "            car_img = cv2.imread(gal['file_path'])\n",
        "            feat_small = helper_small.infer(car_img)\n",
        "            feat_middle = helper_middle.infer(car_img)\n",
        "            feat_large = helper_large.infer(car_img)\n",
        "            small_distance = calc_distance(feat1_small, feat_small)\n",
        "            middle_distance = calc_distance(feat1_middle, feat_middle)\n",
        "            large_distance = calc_distance(feat1_large, feat_large)\n",
        "            result_df.loc[idx,:] = [case_idx, cls, gal['class'], small_distance, middle_distance, large_distance,  gal['file_path'],0]\n",
        "        num += 1            \n",
        "        case_idx +=1\n",
        "\n",
        "        print(num)\n",
        "\n",
        "    \n",
        "    result_df.loc[result_df[result_df['target_model'] == result_df['car_model']].index, 'same'] = 1\n",
        "    \n",
        "    return result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixI1AJJIXlum"
      },
      "outputs": [],
      "source": [
        "df = random_df(sample_num=90)\n",
        "df.to_csv('/content/drive/MyDrive/공유폴더/csv/정면_다른색.csv')\n",
        "df = random_df(angle = '후면')\n",
        "df.to_csv('/content/drive/MyDrive/공유폴더/csv/후면_다른색.csv')\n",
        "df = random_df(angle = '측면')\n",
        "df.to_csv('/content/drive/MyDrive/공유폴더/csv/측면_다른색.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "md91gqRGNu_K"
      },
      "outputs": [],
      "source": [
        "angle_df = cropped_img_df[cropped_img_df['angle'] == '정면'].reset_index(drop=True)\n",
        "angle_df['clsss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRDGNXnUSF2y"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import random\n",
        "import cv2\n",
        "\n",
        "def random_df(angle = '정면', standard = None, same = True, sample_num=100, path_df = cropped_img_df, unique_df = unique_df):\n",
        "    \n",
        "    path_dict = {'small':'/content/drive/MyDrive/공유폴더/fast-reid/outputs/VehicleID_Baseline/baseline_R50.onnx',\n",
        "                 'middle':'/content/drive/MyDrive/공유폴더/fast-reid/outputs/VeRi_Baseline/baseline_R50.onnx',\n",
        "                 'large':'/content/drive/MyDrive/공유폴더/fast-reid/outputs/VERI_Wild_Baseline/baseline_R50.onnx'\n",
        "                 }\n",
        "    \n",
        "    idx = 0\n",
        "    result_df = pd.DataFrame(columns = ['case', 'target_model', 'car_model', 'small_distance', 'middle_distance', 'large_distance', 'file_path', 'same'])\n",
        "    case_idx = 0\n",
        "\n",
        "    angle_df = path_df[path_df['angle'] == angle].reset_index(drop=True)\n",
        "    path_v = angle_df['class'].value_counts()\n",
        "    cls_over5= path_v[path_v>=5].keys()\n",
        "    cls_over5= random.sample(list(path_v[path_v>=5].keys()),100)\n",
        "    \n",
        "    helper_small = ReidHelper(path_dict['small'])\n",
        "    helper_middle = ReidHelper(path_dict['middle'])\n",
        "    helper_large = ReidHelper(path_dict['large'])\n",
        "    \n",
        "\n",
        "    for cls in cls_over5:\n",
        "        select_path = angle_df[angle_df['class']== cls]['file_path'].values\n",
        "        select_length = len(select_path)\n",
        "        if standard != None:\n",
        "            select_standard = angle_df[angle_df['class']== cls][standard].values[0]\n",
        "\n",
        "        feat1_small = None\n",
        "        feat1_middle = None\n",
        "        feat1_large = None\n",
        "\n",
        "        for index, file_path in enumerate(select_path):\n",
        "            car_img = cv2.imread(file_path)\n",
        "            feat_small = helper_small.infer(car_img)\n",
        "            feat_middle = helper_middle.infer(car_img)\n",
        "            feat_large = helper_large.infer(car_img)\n",
        "\n",
        "            if index == 0:\n",
        "                idx +=1\n",
        "                feat1_small = feat_small\n",
        "                feat1_middle =feat_middle\n",
        "                feat1_large = feat_large\n",
        "                ex = angle_df[angle_df['class']==cls].iloc[0]\n",
        "                result_df.loc[idx,:] = [case_idx, cls, cls, 0, 0, 0,  file_path, 0]\n",
        "                \n",
        "            else:\n",
        "                idx +=1\n",
        "                small_distance = calc_distance(feat1_small, feat_small)\n",
        "                middle_distance = calc_distance(feat1_middle, feat_middle)\n",
        "                large_distance = calc_distance(feat1_large, feat_large)\n",
        "                result_df.loc[idx,:] = [case_idx, cls, cls, small_distance, middle_distance, large_distance,  file_path, 0]\n",
        "                \n",
        "        \n",
        "        if same:\n",
        "            select_can = list(angle_df[(angle_df['class'] != cls) & (angle_df[standard] == select_standard)].index)\n",
        "        else:\n",
        "            select_can = list(angle_df[(angle_df['class'] != cls) & (angle_df[standard] != select_standard)].index)\n",
        "\n",
        "        random100 = random.sample(select_can, sample_num - select_length)\n",
        "\n",
        "        for gal_index in random100:\n",
        "            idx += 1\n",
        "            gal = angle_df.loc[gal_index]\n",
        "            car_img = cv2.imread(gal['file_path'])\n",
        "            feat_small = helper_small.infer(car_img)\n",
        "            feat_middle = helper_middle.infer(car_img)\n",
        "            feat_large = helper_large.infer(car_img)\n",
        "            small_distance = calc_distance(feat1_small, feat_small)\n",
        "            middle_distance = calc_distance(feat1_middle, feat_middle)\n",
        "            large_distance = calc_distance(feat1_large, feat_large)\n",
        "            result_df.loc[idx,:] = [case_idx, cls, gal['class'], small_distance, middle_distance, large_distance,  gal['file_path'],0]        \n",
        "        case_idx +=1\n",
        "\n",
        "        print(case_idx)\n",
        "\n",
        "    \n",
        "    result_df.loc[result_df[result_df['target_model'] == result_df['car_model']].index, 'same'] = 1\n",
        "    \n",
        "    return result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_b20DWSpSsQI"
      },
      "outputs": [],
      "source": [
        "df = random_df(standard = 'size')\n",
        "df.to_csv('/content/drive/MyDrive/공유폴더/csv/정면_같은크기.csv')\n",
        "df = random_df(angle = '후면',standard = 'size')\n",
        "df.to_csv('/content/drive/MyDrive/공유폴더/csv/후면_같은크기.csv')\n",
        "df = random_df(angle = '측면',standard = 'size')\n",
        "df.to_csv('/content/drive/MyDrive/공유폴더/csv/측면_같은크기.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2Wj_aIbeeix"
      },
      "outputs": [],
      "source": [
        "df = random_df(standard = 'size',same=False)\n",
        "df.to_csv('/content/drive/MyDrive/공유폴더/csv/정면_다른크기.csv')\n",
        "df = random_df(angle = '후면',standard = 'size',same=False)\n",
        "df.to_csv('/content/drive/MyDrive/공유폴더/csv/후면_다른크기.csv')\n",
        "df = random_df(angle = '측면',standard = 'size',same=False)\n",
        "df.to_csv('/content/drive/MyDrive/공유폴더/csv/측면_다른크기.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKLhGzvft6OM"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import random\n",
        "import cv2\n",
        "\n",
        "def random_df(angle = '정면', standard = None, same = True, sample_num=100, path_df = cropped_img_df, unique_df = unique_df):\n",
        "    \n",
        "    path_dict = {'small':'/content/drive/MyDrive/공유폴더/fast-reid/outputs/VeRi_Baseline/baseline_R50.onnx',\n",
        "                'middle':'/content/drive/MyDrive/공유폴더/fast-reid/outputs/VehicleID_Baseline/baseline_R50.onnx',\n",
        "                'large':'/content/drive/MyDrive/공유폴더/fast-reid/outputs/VERI_Wild_Baseline/baseline_R50.onnx'\n",
        "                 }\n",
        "    \n",
        "    idx = 0\n",
        "    result_df = pd.DataFrame(columns = ['case', 'target_model', 'car_model', 'small_distance', 'middle_distance', 'large_distance', 'file_path', 'same'])\n",
        "    case_idx = 0\n",
        "\n",
        "    angle_df = path_df[path_df['angle'] == angle].reset_index(drop=True)\n",
        "    path_v = angle_df['class'].value_counts()\n",
        "    cls_over5= path_v[path_v>=5].keys()\n",
        "    cls_over5= random.sample(list(path_v[path_v>=5].keys()),100)\n",
        "    \n",
        "    helper_small = ReidHelper(path_dict['small'])\n",
        "    helper_middle = ReidHelper(path_dict['middle'])\n",
        "    helper_large = ReidHelper(path_dict['large'])\n",
        "    \n",
        "\n",
        "    for cls in cls_over5:\n",
        "        select_path = angle_df[angle_df['class']== cls]['file_path'].values\n",
        "        select_path = random.sample(list(angle_df[angle_df['class']== cls]['file_path'].values), 5)\n",
        "        if standard != None:\n",
        "            select_standard = angle_df[angle_df['class']== cls][standard].values[0]\n",
        "\n",
        "        feat1_small = None\n",
        "        feat1_middle = None\n",
        "        feat1_large = None\n",
        "\n",
        "        for index, file_path in enumerate(select_path):\n",
        "            car_img = cv2.imread(file_path)\n",
        "            feat_small = helper_small.infer(car_img)\n",
        "            feat_middle = helper_middle.infer(car_img)\n",
        "            feat_large = helper_large.infer(car_img)\n",
        "\n",
        "            if index == 0:\n",
        "                idx +=1\n",
        "                feat1_small = feat_small\n",
        "                feat1_middle =feat_middle\n",
        "                feat1_large = feat_large\n",
        "                ex = angle_df[angle_df['class']==cls].iloc[0]\n",
        "                result_df.loc[idx,:] = [case_idx, cls, cls, 0, 0, 0,  file_path, 0]\n",
        "                \n",
        "            else:\n",
        "                idx +=1\n",
        "                small_distance = calc_distance(feat1_small, feat_small)\n",
        "                middle_distance = calc_distance(feat1_middle, feat_middle)\n",
        "                large_distance = calc_distance(feat1_large, feat_large)\n",
        "                result_df.loc[idx,:] = [case_idx, cls, cls, small_distance, middle_distance, large_distance,  file_path, 0]\n",
        "                \n",
        "        if standard:\n",
        "            if same:\n",
        "                select_can = list(angle_df[(angle_df['class'] != cls) & (angle_df[standard] == select_standard)].index)\n",
        "            else:\n",
        "                select_can = list(angle_df[(angle_df['class'] != cls) & (angle_df[standard] != select_standard)].index)\n",
        "        \n",
        "        else:\n",
        "            select_can = list(angle_df[angle_df['class'] != cls].index)\n",
        "        \n",
        "        random100 = random.sample(select_can, sample_num - 5)\n",
        "\n",
        "        for gal_index in random100:\n",
        "            idx += 1\n",
        "            gal = angle_df.loc[gal_index]\n",
        "            car_img = cv2.imread(gal['file_path'])\n",
        "            feat_small = helper_small.infer(car_img)\n",
        "            feat_middle = helper_middle.infer(car_img)\n",
        "            feat_large = helper_large.infer(car_img)\n",
        "            small_distance = calc_distance(feat1_small, feat_small)\n",
        "            middle_distance = calc_distance(feat1_middle, feat_middle)\n",
        "            large_distance = calc_distance(feat1_large, feat_large)\n",
        "            result_df.loc[idx,:] = [case_idx, cls, gal['class'], small_distance, middle_distance, large_distance,  gal['file_path'],0]        \n",
        "        case_idx +=1\n",
        "\n",
        "        print(case_idx)\n",
        "\n",
        "    \n",
        "    result_df.loc[result_df[result_df['target_model'] == result_df['car_model']].index, 'same'] = 1\n",
        "    \n",
        "    return result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0HuY3_Wvwld",
        "outputId": "0ef5c18f-8514-4479-f4dd-909ed4ff5f2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n"
          ]
        }
      ],
      "source": [
        "df = random_df()\n",
        "df.to_csv('/content/drive/MyDrive/공유폴더/csv/진짜비교/정면.csv')\n",
        "df = random_df(angle = '후면')\n",
        "df.to_csv('/content/drive/MyDrive/공유폴더/csv/진짜비교/후면.csv')\n",
        "df = random_df(angle = '측면')\n",
        "df.to_csv('/content/drive/MyDrive/공유폴더/csv/진짜비교/측면.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7p93EZJxV5l",
        "outputId": "98371906-f831-47bf-8833-2b813b352cf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n"
          ]
        }
      ],
      "source": [
        "df = random_df(standard = 'size')\n",
        "df.to_csv('/content/drive/MyDrive/공유폴더/csv/진짜비교/정면_같은크기.csv')\n",
        "df = random_df(angle = '후면',standard = 'size')\n",
        "df.to_csv('/content/drive/MyDrive/공유폴더/csv/진짜비교/후면_같은크기.csv')\n",
        "df = random_df(angle = '측면',standard = 'size')\n",
        "df.to_csv('/content/drive/MyDrive/공유폴더/csv/진짜비교/측면_같은크기.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvRkbhF00ZG-",
        "outputId": "bd954231-4eef-43db-a775-c77e577aca35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n"
          ]
        }
      ],
      "source": [
        "df = random_df(standard = 'size', same= False)\n",
        "df.to_csv('/content/drive/MyDrive/공유폴더/csv/진짜비교/정면_다른크기.csv')\n",
        "df = random_df(angle = '후면',standard = 'size', same= False)\n",
        "df.to_csv('/content/drive/MyDrive/공유폴더/csv/진짜비교/후면_다른크기.csv')\n",
        "df = random_df(angle = '측면',standard = 'size', same= False)\n",
        "df.to_csv('/content/drive/MyDrive/공유폴더/csv/진짜비교/측면_다른크기.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4br27MMItnA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GFHq4x53ks2",
        "outputId": "68678be4-4051-4146-e60f-9caff756a976"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n"
          ]
        }
      ],
      "source": [
        "df = random_df(standard = 'color',same= False)\n",
        "df.to_csv('/content/drive/MyDrive/공유폴더/csv/진짜비교/정면_다른색상.csv')\n",
        "df = random_df(angle = '후면',standard = 'color' ,same= False)\n",
        "df.to_csv('/content/drive/MyDrive/공유폴더/csv/진짜비교/후면_다른색상.csv')\n",
        "df = random_df(angle = '측면',standard = 'color' ,same= False)\n",
        "df.to_csv('/content/drive/MyDrive/공유폴더/csv/진짜비교/측면_다른색상.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpfYebt2tVd0"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import random\n",
        "import cv2\n",
        "\n",
        "def random_df(angle = '정면', standard = None, same = True, sample_num=100, path_df = cropped_img_df, unique_df = unique_df):\n",
        "    \n",
        "    path_dict = {'small':'/content/drive/MyDrive/공유폴더/fast-reid/outputs/VeRi_Baseline/baseline_R50.onnx',\n",
        "                'middle':'/content/drive/MyDrive/공유폴더/fast-reid/outputs/VehicleID_Baseline/baseline_R50.onnx',\n",
        "                'large':'/content/drive/MyDrive/공유폴더/fast-reid/outputs/VERI_Wild_Baseline/baseline_R50.onnx'\n",
        "                 }\n",
        "    \n",
        "    idx = 0\n",
        "    result_df = pd.DataFrame(columns = ['case', 'target_model', 'car_model', 'small_distance', 'middle_distance', 'large_distance', 'file_path', 'same'])\n",
        "    case_idx = 0\n",
        "\n",
        "    angle_df = path_df[(path_df['angle'] == angle) & (path_df['color'] != '빨강')].reset_index(drop=True)\n",
        "    path_v = angle_df['class'].value_counts()\n",
        "    cls_over5= path_v[path_v>=5].keys()\n",
        "    cls_over5= random.sample(list(path_v[path_v>=5].keys()),100)\n",
        "    \n",
        "    helper_small = ReidHelper(path_dict['small'])\n",
        "    helper_middle = ReidHelper(path_dict['middle'])\n",
        "    helper_large = ReidHelper(path_dict['large'])\n",
        "    \n",
        "\n",
        "    for cls in cls_over5:\n",
        "        select_path = angle_df[angle_df['class']== cls]['file_path'].values\n",
        "        select_path = random.sample(list(angle_df[angle_df['class']== cls]['file_path'].values), 5)\n",
        "        if standard != None:\n",
        "            select_standard = angle_df[angle_df['class']== cls][standard].values[0]\n",
        "\n",
        "        feat1_small = None\n",
        "        feat1_middle = None\n",
        "        feat1_large = None\n",
        "\n",
        "        for index, file_path in enumerate(select_path):\n",
        "            car_img = cv2.imread(file_path)\n",
        "            feat_small = helper_small.infer(car_img)\n",
        "            feat_middle = helper_middle.infer(car_img)\n",
        "            feat_large = helper_large.infer(car_img)\n",
        "\n",
        "            if index == 0:\n",
        "                idx +=1\n",
        "                feat1_small = feat_small\n",
        "                feat1_middle =feat_middle\n",
        "                feat1_large = feat_large\n",
        "                ex = angle_df[angle_df['class']==cls].iloc[0]\n",
        "                result_df.loc[idx,:] = [case_idx, cls, cls, 0, 0, 0,  file_path, 0]\n",
        "                \n",
        "            else:\n",
        "                idx +=1\n",
        "                small_distance = calc_distance(feat1_small, feat_small)\n",
        "                middle_distance = calc_distance(feat1_middle, feat_middle)\n",
        "                large_distance = calc_distance(feat1_large, feat_large)\n",
        "                result_df.loc[idx,:] = [case_idx, cls, cls, small_distance, middle_distance, large_distance,  file_path, 0]\n",
        "                \n",
        "        if standard:\n",
        "            if same:\n",
        "                select_can = list(angle_df[(angle_df['class'] != cls) & (angle_df[standard] == select_standard)].index)\n",
        "            else:\n",
        "                select_can = list(angle_df[(angle_df['class'] != cls) & (angle_df[standard] != select_standard)].index)\n",
        "        \n",
        "        else:\n",
        "            select_can = list(angle_df[angle_df['class'] != cls].index)\n",
        "        \n",
        "        random100 = random.sample(select_can, sample_num - 5)\n",
        "\n",
        "        for gal_index in random100:\n",
        "            idx += 1\n",
        "            gal = angle_df.loc[gal_index]\n",
        "            car_img = cv2.imread(gal['file_path'])\n",
        "            feat_small = helper_small.infer(car_img)\n",
        "            feat_middle = helper_middle.infer(car_img)\n",
        "            feat_large = helper_large.infer(car_img)\n",
        "            small_distance = calc_distance(feat1_small, feat_small)\n",
        "            middle_distance = calc_distance(feat1_middle, feat_middle)\n",
        "            large_distance = calc_distance(feat1_large, feat_large)\n",
        "            result_df.loc[idx,:] = [case_idx, cls, gal['class'], small_distance, middle_distance, large_distance,  gal['file_path'],0]        \n",
        "        case_idx +=1\n",
        "\n",
        "        print(case_idx)\n",
        "\n",
        "    \n",
        "    result_df.loc[result_df[result_df['target_model'] == result_df['car_model']].index, 'same'] = 1\n",
        "    \n",
        "    return result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEWSdtAYt1Ud",
        "outputId": "a146b928-c448-4320-cad8-430975bcaa64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n"
          ]
        }
      ],
      "source": [
        "df = random_df(standard = 'color')\n",
        "df.to_csv('/content/drive/MyDrive/공유폴더/csv/진짜비교/정면_같은색상.csv')\n",
        "df = random_df(angle = '후면',standard = 'color')\n",
        "df.to_csv('/content/drive/MyDrive/공유폴더/csv/진짜비교/후면_같은색상.csv')\n",
        "df = random_df(angle = '측면',standard = 'color')\n",
        "df.to_csv('/content/drive/MyDrive/공유폴더/csv/진짜비교/측면_같은색상.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}